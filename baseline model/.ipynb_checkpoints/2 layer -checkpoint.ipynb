{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import time\n",
    "import data_processing\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_hidden_1=155,\n",
    "num_hidden_2=81,\n",
    "num_hidden_3=27,\n",
    "num_hidden_4=9,\n",
    "num_hidden_5=3,\n",
    "\n",
    "'''\n",
    "\n",
    "class autoencoder(object):# 155 27 128 101 74\n",
    "    def __init__(self,num_epochs=100, display_step=100, learning_rate=0.1, batch_size=100,\n",
    "                 denoising=False, new_poll_weight=0.002,masking=0, num_layers=3, num_hidden_1=155,\n",
    "                 num_hidden_2=81,num_hidden_3=27,num_hidden_4=9,num_hidden_5=3,continue_from_saved=False, time_decay=1):\n",
    "\n",
    "        self.data_provider = data_processing.data_provider('/Users/caesar/PycharmProjects/my_honours_project/src/this_that.json')\n",
    "        self.data_provider.parse()\n",
    "        # Interactions are fed as binary but using decimal helps with adding 2 interactions together\n",
    "        self.interaction_dict = {'skips': 16,\n",
    "            'owns': 8,\n",
    "            'tracks': 4,\n",
    "            'comment': 2,\n",
    "            'vote': 1\n",
    "        }\n",
    "\n",
    "        self.polls = self.data_provider.polls  # [:50]\n",
    "        self.num_engagements = len(self.interaction_dict)\n",
    "\n",
    "        self.num_input = len(self.polls) * self.num_engagements\n",
    "        tf.set_random_seed(1)\n",
    "\n",
    "        self.users = self.data_provider.users#[:50]\n",
    "\n",
    "        self.test_polls = self.data_provider.polls#[500:]\n",
    "        self.num_epochs = num_epochs # initial training eppchs given training data\n",
    "        self.display_step = display_step # display training loss every x epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.denoising = denoising # whether to add noise to the input vectors - might help with accidental interactions\n",
    "        self.new_poll_weight = new_poll_weight # How much weight new polls are given in the output layer (gives new polls some initial traction)\n",
    "        self.masking = masking # TODO: Add masking to data to make synthetic users with less interactions and see if it helps\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden_1 = num_hidden_1\n",
    "        self.num_hidden_2 = num_hidden_2\n",
    "        self.num_hidden_3 = num_hidden_3\n",
    "        self.num_hidden_4 = num_hidden_4\n",
    "        self.num_hidden_5 = num_hidden_5\n",
    "        self.continue_from_saved = continue_from_saved\n",
    "        self.train= self.data_provider.train\n",
    "        self.test = self.data_provider.test\n",
    "        self.validation = self.data_provider.validation\n",
    "        self.test_users = []\n",
    "        self.time_decay = time_decay\n",
    "        self.X = tf.compat.v1.placeholder(\"float\", [None, None])\n",
    "        self.Y = tf.compat.v1.placeholder(\"float\", [None, None])\n",
    "        self.saver = None\n",
    "\n",
    "        self.compressed_train = []\n",
    "        self.compressed_test = []\n",
    "\n",
    "        self.weights2 = {\n",
    "            'encoder_h1': tf.Variable(tf.random_normal([self.num_input, self.num_hidden_1])),\n",
    "            'encoder_h2': tf.Variable(tf.random_normal([self.num_hidden_1, self.num_hidden_2])),\n",
    "            'encoder_h3': tf.Variable(tf.random_normal([self.num_hidden_2, self.num_hidden_3])),\n",
    "            'encoder_h4': tf.Variable(tf.random_normal([self.num_hidden_3, self.num_hidden_4])),\n",
    "            'encoder_h5': tf.Variable(tf.random_normal([self.num_hidden_4, self.num_hidden_5])),\n",
    "\n",
    "            'decoder_h1': tf.Variable(tf.random_normal([self.num_hidden_2, self.num_hidden_1])),\n",
    "            'decoder_h2': tf.Variable(tf.random_normal([self.num_hidden_1, self.num_input])),\n",
    "            'decoder_h3': tf.Variable(tf.random_normal([self.num_hidden_3, self.num_hidden_2])),\n",
    "            'decoder_h4': tf.Variable(tf.random_normal([self.num_hidden_2, self.num_hidden_1])),\n",
    "            'decoder_h5': tf.Variable(tf.random_normal([self.num_hidden_1, self.num_input])),\n",
    "        }\n",
    "        self.biases2 = {\n",
    "            'encoder_b1': tf.Variable(tf.random_normal([self.num_hidden_1])),\n",
    "            'encoder_b2': tf.Variable(tf.random_normal([self.num_hidden_2])),\n",
    "            'encoder_b3': tf.Variable(tf.random_normal([self.num_hidden_3])),\n",
    "\n",
    "            'encoder_b4': tf.Variable(tf.random_normal([self.num_hidden_4])),\n",
    "            'encoder_b5': tf.Variable(tf.random_normal([self.num_hidden_5])),\n",
    "\n",
    "            'decoder_b1': tf.Variable(tf.random_normal([self.num_hidden_1])),\n",
    "            'decoder_b2': tf.Variable(tf.random_normal([self.num_input])),\n",
    "            'decoder_b3': tf.Variable(tf.random_normal([self.num_hidden_2])),\n",
    "            'decoder_b4': tf.Variable(tf.random_normal([self.num_hidden_1])),\n",
    "            'decoder_b5': tf.Variable(tf.random_normal([self.num_input])),\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "        self.encoder_op = self.encoder(self.X)\n",
    "        self.decoder_op = self.decoder(self.encoder_op)\n",
    "        self.setup_graph()\n",
    "\n",
    "        self.train_and_predict()\n",
    "\n",
    "    def encoder(self, x):\n",
    "        layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weights2['encoder_h1']),self.biases2['encoder_b1']))\n",
    "        layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, self.weights2['encoder_h2']),self.biases2['encoder_b2']))\n",
    "        #layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, self.weights2['encoder_h3']), self.biases2['encoder_b3']))\n",
    "        #layer_4 = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, self.weights2['encoder_h4']), self.biases2['encoder_b4']))\n",
    "        #layer_5 = tf.nn.sigmoid(tf.add(tf.matmul(layer_4, self.weights2['encoder_h5']), self.biases2['encoder_b5']))\n",
    "        return layer_2\n",
    "\n",
    "    def decoder(self, x):\n",
    "        layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weights2['decoder_h1']), self.biases2['decoder_b1']))\n",
    "        layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, self.weights2['decoder_h2']),self.biases2['decoder_b2']))\n",
    "        #layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weights2['decoder_h1']), self.biases2['decoder_b1']))\n",
    "        #layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, self.weights2['decoder_h2']),self.biases2['decoder_b2']))\n",
    "        #layer_3 = tf.nn.sigmoid(tf.add(tf.matmul(layer_2, self.weights2['decoder_h3']), self.biases2['decoder_b3']))\n",
    "        #layer_4 = tf.nn.sigmoid(tf.add(tf.matmul(layer_3, self.weights2['decoder_h4']), self.biases2['decoder_b4']))\n",
    "        #layer_5 = tf.nn.sigmoid(tf.add(tf.matmul(layer_4, self.weights2['decoder_h5']), self.biases2['decoder_b5']))\n",
    "        return layer_2\n",
    "\n",
    "    def setup_graph(self):\n",
    "\n",
    "        # Prediction\n",
    "        self.y_pred = self.decoder_op\n",
    "\n",
    "        self.y_true = self.Y\n",
    "        self.loss = self._loss()\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)\n",
    "\n",
    "        self.init = tf.global_variables_initializer()\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def _loss(self):\n",
    "        return tf.reduce_mean(tf.pow(self.y_true - self.y_pred, 2))\n",
    "\n",
    "    def train_and_predict(self, save=True):\n",
    "        gc.collect()\n",
    "\n",
    "        f = open(\"guru99.txt\", \"w+\")\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            train_loss = []\n",
    "            validation_loss = []\n",
    "            t0 = time.time()\n",
    "\n",
    "            for i in range(0,self.num_epochs):\n",
    "\n",
    "                batch_x = self.train[np.random.choice(self.train.shape[0], self.batch_size, replace=True), :]\n",
    "                batch_y = np.copy(batch_x)\n",
    "\n",
    "                _, l = sess.run([self.optimizer, self.loss], feed_dict={self.X: batch_x, self.Y: batch_y})\n",
    "                train_loss.append(l)\n",
    "\n",
    "\n",
    "                # print(\"the minibatch loss for epoch %d is %f\"% (i,l));\n",
    "\n",
    "                f.write(\"%f\\r\\n\" % l)\n",
    "\n",
    "                l = sess.run(self.loss, feed_dict={self.X: self.validation, self.Y: self.validation})\n",
    "                validation_loss.append(l)\n",
    "                if save and (i == 0 or i % self.display_step == 0):\n",
    "                    self.saver.save(sess, 'refactored/model.ckpt')\n",
    "\n",
    "            train_encoder_result = sess.run(self.encoder_op, feed_dict={self.X: self.train})\n",
    "            test_encoder_result = sess.run(self.encoder_op, feed_dict={self.X: self.test})\n",
    "\n",
    "            print()\n",
    "\n",
    "            self.compressed_train = np.copy(train_encoder_result)\n",
    "            self.compressed_test = np.copy(test_encoder_result)\n",
    "            # print(test_encoder_result)\n",
    "\n",
    "            xs = np.arange(1,self.num_epochs+1,1)\n",
    "            ys = train_loss\n",
    "            fig, ax = plt.subplots(figsize=(12, 8))\n",
    "            ax.plot(xs, ys,color = 'b')\n",
    "            xs = np.arange(1, self.num_epochs+1, 1)\n",
    "            ys = validation_loss\n",
    "            plt.plot(xs, ys,color = 'r')\n",
    "            plt.show()\n",
    "\n",
    "            print('autoencoder finished')\n",
    "        sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_to_dec(recommendering_user):\n",
    "    dec_array = []\n",
    "    for i in range(636):\n",
    "        first = i * 5\n",
    "        second = i * 5 + 1\n",
    "        third = i * 5 + 2\n",
    "        fourth = i * 5 + 3\n",
    "        fifth = i * 5 + 4\n",
    "\n",
    "        value = recommendering_user[first] * (2 ** 4) + recommendering_user[second] * (2 ** 3) + \\\n",
    "                recommendering_user[third] * (2 ** 2) + recommendering_user[fourth] * (2 ** 1) + recommendering_user[fifth]\n",
    "\n",
    "        dec_array.append(value)\n",
    "\n",
    "    return dec_array\n",
    "\n",
    "def binary_matrix_to_dec_matrix(recommendering_user):\n",
    "    result = []\n",
    "    for i in range(len(recommendering_user)):\n",
    "        result.append( binary_to_dec(recommendering_user[i]) )\n",
    "    return result\n",
    "                                                        # true_positive,false_negative,false_positive\n",
    "def loss_function_accuracy_difference_between_true_label_and_probability(training_data_accuracy,true_label,true_positive,false_negative,false_positive):\n",
    "\n",
    "    if true_label == 16 :\n",
    "        normalised_true_label = 0\n",
    "    else:\n",
    "        normalised_true_label = 1\n",
    "    result = np.abs((training_data_accuracy-normalised_true_label))\n",
    "\n",
    "    # prediction is 1 whereas true label is 1\n",
    "    if training_data_accuracy > 0.5 and normalised_true_label == 1:\n",
    "        true_positive = true_positive + 1\n",
    "\n",
    "    if training_data_accuracy < 0.5 and normalised_true_label == 1:\n",
    "        false_negative = false_negative + 1\n",
    "\n",
    "    if training_data_accuracy > 0.5 and normalised_true_label == 0:\n",
    "        false_positive = false_positive+1\n",
    "\n",
    "    return result,true_positive,false_negative,false_positive\n",
    "\n",
    "def loss_function_accuracy_difference_between_true_label_and_prediction(training_data_accuracy,true_label,true_positive,false_negative,false_positive):\n",
    "    if true_label == 16 :\n",
    "        normalised_true_label = 0\n",
    "    else:\n",
    "        normalised_true_label = 1\n",
    "\n",
    "    if training_data_accuracy>0.5:\n",
    "        predicted_value = 1\n",
    "    else:\n",
    "        predicted_value = 0\n",
    "    result = np.abs((normalised_true_label-predicted_value))\n",
    "\n",
    "    # prediction is 1 whereas true label is 1\n",
    "    if training_data_accuracy > 0.5 and normalised_true_label == 1:\n",
    "        true_positive = true_positive + 1\n",
    "\n",
    "    if training_data_accuracy < 0.5 and normalised_true_label == 1:\n",
    "        false_negative = false_negative + 1\n",
    "\n",
    "    if training_data_accuracy > 0.5 and normalised_true_label == 0:\n",
    "        false_positive = false_positive + 1\n",
    "\n",
    "    return result,true_positive,false_negative,false_positive\n",
    "\n",
    "def fill_the_clusters(label_pred):\n",
    "    clusters = {}\n",
    "    for index, cluster_index in enumerate(label_pred):\n",
    "        if cluster_index not in clusters.keys():\n",
    "            clusters[cluster_index] = [ original_training_data[index] ]\n",
    "        else:\n",
    "            clusters[cluster_index].append(original_training_data[index])\n",
    "    return clusters\n",
    "\n",
    "def run_kmeans(n_clusters):\n",
    "    clusters = {}\n",
    "    estimator = KMeans(n_clusters=n_clusters)\n",
    "    estimator.fit(compressed_training_data)\n",
    "    label_pred = estimator.labels_\n",
    "    centroids = estimator.cluster_centers_\n",
    "    centroids = np.asarray(centroids)\n",
    "\n",
    "    return estimator,label_pred,centroids\n",
    "\n",
    "def calculate_loss(clusters):\n",
    "\n",
    "    loss_difference_between_true_label_and_probability = []\n",
    "    loss_difference_between_true_label_and_prediction = []\n",
    "\n",
    "\n",
    "    true_positive_1 = 0\n",
    "    false_negative_1 = 0\n",
    "    false_positive_1 = 0\n",
    "\n",
    "    for i in range( len(compressed_testing_data) ):# for every test case\n",
    "\n",
    "        label = estimator.predict(np.reshape(compressed_testing_data[i],(1,-1)))\n",
    "\n",
    "        tempt = np.copy( clusters[label[0]] )\n",
    "\n",
    "        recommendering_user_binary = np.copy(original_testing_data[i])\n",
    "\n",
    "        recommendering_user = binary_to_dec(recommendering_user_binary)\n",
    "\n",
    "        new_matrix = binary_matrix_to_dec_matrix( tempt )\n",
    "\n",
    "        row_index = np.shape(new_matrix)[0]\n",
    "\n",
    "        poll_num = len(recommendering_user)\n",
    "\n",
    "        individual_accuracy_1 = []\n",
    "        individual_accuracy_2 = []\n",
    "\n",
    "        true_positive_1 = 0\n",
    "        false_negative_1 = 0\n",
    "        false_positive_1 = 0\n",
    "\n",
    "        true_positive_2 = 0\n",
    "        false_negative_2 = 0\n",
    "        false_positive_2 = 0\n",
    "\n",
    "        for j in range(poll_num): # for every poll of this test user\n",
    "            true_label =recommendering_user[j]\n",
    "\n",
    "            true = 0\n",
    "            training_count = 0\n",
    "\n",
    "\n",
    "            if recommendering_user[j] != 0 :\n",
    "                for k in range(row_index):\n",
    "                    new_matrix = np.asarray(new_matrix)\n",
    "                    column = new_matrix[:,j]\n",
    "\n",
    "                    # 16 means the user skips the poll\n",
    "                    if column[k] != 16 and column[k] != 0:\n",
    "                        true = true + 1\n",
    "                    if column[k] !=0:\n",
    "                        training_count = training_count+1\n",
    "\n",
    "                if training_count != 0 and recommendering_user[j] != 0:\n",
    "                    training_data_accuracy = true/training_count\n",
    "\n",
    "                    the_loss_of_each_poll_1,true_positive_1,false_negative_1,false_positive_1 = loss_function_accuracy_difference_between_true_label_and_probability(training_data_accuracy,true_label,true_positive_1,false_negative_1,false_positive_1)\n",
    "                    the_loss_of_each_poll_2, true_positive_2, false_negative_2, false_positive_2 = loss_function_accuracy_difference_between_true_label_and_prediction(training_data_accuracy, true_label, true_positive_2, false_negative_2, false_positive_2)\n",
    "\n",
    "                    individual_accuracy_1.append(the_loss_of_each_poll_1)\n",
    "                    individual_accuracy_2.append(the_loss_of_each_poll_2)\n",
    "\n",
    "        the_loss_of_a_user_1 = np.average(individual_accuracy_1)\n",
    "        the_loss_of_a_user_2 = np.average(individual_accuracy_2)\n",
    "        loss_difference_between_true_label_and_probability.append(the_loss_of_a_user_1)\n",
    "        loss_difference_between_true_label_and_prediction.append(the_loss_of_a_user_2)\n",
    "\n",
    "    return loss_difference_between_true_label_and_probability,true_positive_1,false_negative_1,false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2\n",
    "\n",
    "\n",
    "def number_of_zero_one_16(column):\n",
    "\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    sixteen =0\n",
    "    for i in column:\n",
    "        if i == 0:\n",
    "            zero = zero + 1\n",
    "\n",
    "        if i ==16:\n",
    "            sixteen = sixteen + 1\n",
    "        else:\n",
    "            one = one + 1\n",
    "    print(\"there are %d non interactions, %d interactions, %d skips\"% (zero,one,sixteen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1021 08:07:04.794322 4454847936 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1021 08:07:04.919706 4454847936 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "a = autoencoder(num_epochs=10000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=9000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=8000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=7000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=6000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=5000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=4000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=3000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=2000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autoencoder(num_epochs=1000, denoising=False, masking=0.5, display_step=200)\n",
    "\n",
    "compressed_training_data = a.compressed_train\n",
    "\n",
    "original_training_data = a.train\n",
    "\n",
    "compressed_testing_data = a.compressed_test\n",
    "original_testing_data = a.test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "overall_true_positive = 0\n",
    "overall_false_negative = 0\n",
    "overall_false_positive = 0\n",
    "\n",
    "#n_clusters =20\n",
    "range_of_cluster = 30\n",
    "train_loss_1 = []\n",
    "train_loss_2 = []\n",
    "\n",
    "recall_list_1 = []\n",
    "precision_list_1 = []\n",
    "\n",
    "recall_list_2 = []\n",
    "precision_list_2 = []\n",
    "\n",
    "for n_clusters in np.arange(1,range_of_cluster+1):\n",
    "\n",
    "    estimator,label_pred,centroids = run_kmeans(n_clusters)\n",
    "\n",
    "    clusters = fill_the_clusters(label_pred)\n",
    "\n",
    "    loss_difference_between_true_label_and_probability, true_positive_1, false_negative_1, false_positive_1,loss_difference_between_true_label_and_prediction, true_positive_2, false_negative_2, false_positive_2 = calculate_loss(clusters)\n",
    "\n",
    "    recall_1 = true_positive_1/(true_positive_1+false_negative_1)\n",
    "    precision_1 = true_positive_1/(true_positive_1+false_positive_1)\n",
    "    recall_list_1.append(recall_1)\n",
    "    precision_list_1.append(precision_1)\n",
    "\n",
    "    recall_2 = true_positive_2 / (true_positive_2 + false_negative_2)\n",
    "    precision_2 = true_positive_2 / (true_positive_2 + false_positive_2)\n",
    "    recall_list_2.append(recall_2)\n",
    "    precision_list_2.append(precision_2)\n",
    "\n",
    "    l = np.average(loss_difference_between_true_label_and_probability)\n",
    "\n",
    "    train_loss_1.append(np.average(loss_difference_between_true_label_and_probability))\n",
    "    train_loss_2.append(np.average(loss_difference_between_true_label_and_prediction))\n",
    "\n",
    "\n",
    "xs = np.arange(1,range_of_cluster+1)\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "train_loss_1 = np.reshape(train_loss_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, train_loss_1)\n",
    "ax.set_xlabel('the value of k')\n",
    "ax.set_ylabel('difference between prediction and true label')\n",
    "ax.title.set_text('train_loss_1,difference between prediction and true label')\n",
    "\n",
    "fig, bx = plt.subplots(figsize=(12, 8))\n",
    "train_loss_2 = np.reshape(train_loss_2,(range_of_cluster,-1))\n",
    "bx.plot(xs, train_loss_2)\n",
    "bx.set_xlabel('the value of k')\n",
    "bx.set_ylabel('difference between probability and true label')\n",
    "bx.title.set_text('train_loss_2,difference between probability and true label')\n",
    "\n",
    "fig, cx = plt.subplots(figsize=(12, 8))\n",
    "recall_list_1 = np.reshape(recall_list_1,(range_of_cluster,-1))\n",
    "cx.plot(xs, recall_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('recall_loss_function1')\n",
    "cx.title.set_text('recall')\n",
    "# fig, cx = plt.subplots(figsize=(12, 8))\n",
    "# recall_list_2 = np.reshape(recall_list_2,(range_of_cluster,-1))\n",
    "# cx.plot(xs, recall_list_2)\n",
    "# cx.set_xlabel('the value of k')\n",
    "# cx.set_ylabel('recall_2')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_1 = np.reshape(precision_list_1,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_1)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_1')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "precision_list_2 = np.reshape(precision_list_2,(range_of_cluster,-1))\n",
    "ax.plot(xs, precision_list_2)\n",
    "cx.set_xlabel('the value of k')\n",
    "cx.set_ylabel('precision_2')\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
